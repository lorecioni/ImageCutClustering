\section{Results}

Let's explore the test phase and see the results in detail. Initially we ran debug tests on our personal pc by porter quickly modify some code.

All tests will be shown below were performed on a single machine that has enabled us to work with much larger data in less time. The machine used is composed of two Xeon processors for a total of 16 cores \@ 2, 80Ghz and 48 Gb of RAM.

The tests were performed on a growing number of scans, each containing a maximum of 50 lines from which we extract the word that represents the State. For each number of different scans have been tried the three possible distances calculation: only LCS, only L1 (Euclidean distance) and LCS and L1 combined together.

The data collected for each test are as follows:
\begin{itemize}
\item \textbf{Number of scans}: the number of scans that was carried out the test.
\item \textbf{Estimated words}: the number of words estimated on the basis of the number of scans.
\item\textbf{Extracted words}: the number of words actually mined and processed, as well as a percentage.
\item \textbf{Number of clusters}: the number of clusters created in process.
\item \textbf{Features extraction time}: the time, in seconds, required for the extraction of features from the words.
\item \textbf{Evaluating distances time}: the time, in seconds, required to generate the similarity matrix with the distances between all the words extracted.
\item \textbf{Clustering time}: the time, in seconds, required for the creation of clusters.
\item \textbf{Running time}: the total execution time, in seconds.
\item \textbf{Correct clusters}: the number of clusters with maximum precision, therefore containing only words equal to each other.
\item \textbf{Correct elements}: the number of words within clusters corrected. Even as a percentage.
\item \textbf{Average precision}: the average precision of the accuracy of individual clusters, as a percentage.
\item \textbf{Precision}: the accuracy of the result, the average accuracy of individual clusters weighted with the number of words.
\end{itemize}

In the next table we're going to show the main results for the tests. 

\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabular}{|l | c | c | c | c | c |} 
 \hline 
 & \multicolumn{1}{p{2cm}|}{\centering\bfseries Estimated \\ words}&  \multicolumn{1}{p{2cm}|}{\centering\bfseries Extracted \\ words} & \multicolumn{1}{p{2cm}|}{\centering\bfseries Number of \\ clusters} & \multicolumn{1}{p{2cm}|}{\centering\bfseries Running \\ time (s)} & \multicolumn{1}{p{2cm}|}{\centering\bfseries Precision \\ (\%)} \\ [0.5ex] 
 \hline\hline
%% label & estimated words & extracted words & clusters & time & precision %%
16 scans (L1) & 800 & 550 & 55 & 15.52 & 58.00\\ 
16 scans (LCS) & 800 & 550 & 71 & 44.39 & 60.00\\ 
16 scans (LCS and L1) & 800 & 550 & 66 & 47.41 & 62.91\\ 
32 scans (L1) & 1600 & 800 & 67 & 38.58 & 52.87\\ 
32 scans (LCS) & 1600 & 800 & 92 & 94.54 & 55.50\\ 
32 scans (LCS and L1) & 1600 & 800 & 86 & 112.90 & 56.25\\ 
80 scans (L1) & 4000 & 2350 & 173 & 221.03 & 63.65\\ 
80 scans (LCS) & 4000 & 2350 & 189 & 1169.72 & 67.49\\ 
80 scans (LCS and L1) & 4000 & 2350 & 199 & 1203.28 & 71.16\\ 
160 scans (L1) & 8000 & 5050 & 425 & 5444.43 & 71.12\\ 
160 scans (LCS) & 8000 & 5050 & 441 & 5629.71 & 74.41\\ 
160 scans (LCS and L1) & 8000 & 5050 & 463 & 6729.62 & 77.94\\ 
700 scans (L1) & 0 & 0 & 0 & 0 & 0\\ 
700 scans (LCS) & 0 & 0 & 0 & 0 & 0\\ 
700 scans (LCS and L1) & 0 & 0 & 0 & 0 & 0\\ 
 \hline
\end{tabular}
\caption{Main results}
\label{table:1}
\end{table}

As we can see in Table \ref{table:1} the number of extracted words is much less than the estimated number of words. This is mainly due to the fact that not all census tables are filled in full: in some cases there are only a few lines or has not been filled in the status column. In other cases, the error is due to a difficulty in removing the word from the scan due to a wrong interpretation of the rows.

As we can see in Figure \ref{fig:precision} the accuracy of the cluster grows with the amount of words extracted. This phenomenon is due to the fact that Affinity Propagation works best with a large number of available data: the greater the number of words, the greater the chances of finding words similar between them, and then combine them within a single cluster.

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.7\textwidth]{images/precisione.png}
\caption{Clustering precision based on number of scans}
\label{fig:precision}
\end{figure}

Now we're going to focus our attention to time. The running time is divided mainly into three distinct phases: time for the extraction of features, time for the creation of similarity matrix (calculation of distances) and clustering.

\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabular}{|l | c | c | c | c |} 
 \hline 
 & \multicolumn{1}{p{2cm}|}{\centering\bfseries Features extraction\\time (s)}&  \multicolumn{1}{p{2cm}|}{\centering\bfseries Evaluating distances\\time (s)} & \multicolumn{1}{p{2cm}|}{\centering\bfseries Clustering\\ time (s)} & \multicolumn{1}{p{2cm}|}{\centering\bfseries Total (s)} \\ [0.5ex] 
 \hline\hline
%% label & features & distances & clusters & total %%
16 scans (L1) & 6.81 & 5.02 & 3.69 & 15.52\\ 
16 scans (LCS) & 6.84 & 34.40 & 3.15 & 44.39\\ 
16 scans (LCS and L1) & 6.84 & 37.32 & 2.85 & 47.41\\ 
32 scans (L1) & 11.54 & 7.22 & 19.82 & 38.58\\ 
32 scans (LCS) & 11.27 & 74.72 & 8.55 & 94.54\\ 
32 scans (LCS and L1) & 11.34 & 89.96 & 11.60 & 112.90\\ 
80 scans (L1) & 33.65 & 69.00 & 118.38 & 221.03\\ 
80 scans (LCS) & 35.13 & 1002.63 & 131.96 & 1169.72\\ 
80 scans (LCS and L1) & 34.70 & 1070.92 & 97.66 & 1203.28\\ 
160 scans (L1) & 70.80 & 313.70 & 5059.93 & 5444.43\\ 
160 scans (LCS) & 68.17 & 4353.85 & 1207.69 & 5629.71\\ 
160 scans (LCS and L1) & 73.10 & 5608.82 & 1047.70 & 6729.62\\ 
700 scans (L1) & 0 & 0 & 0 & 0 \\ 
700 scans (LCS) & 0 & 0 & 0 & 0\\ 
700 scans (LCS and L1) & 0 & 0 & 0 & 0\\ 
 \hline
\end{tabular}
\caption{Running time}
\label{table:2}
\end{table}

As we can see in Table \ref{table:2} the computational time is mainly due to the construction phase of similarity matrix, so the calculation of distances. This occurs especially in calculating LCS distance due to the fact that structural strings of words are very long and the cost of the algorithm is $O(nm)$, with $n$ and $m$ the lengths of the two strings.

Structural long strings characterize better the word (and therefore make more accurate clustering), but involve a longer calculation time.

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.7\textwidth]{images/esecuzione}
\caption{Running time on number of scans}
\label{fig:time}
\end{figure}

A parameter to evaluate the goodness of the newly formed clusters can be the number of clusters that have a maximum precision, or which contain all similar elements between them and properly classified. This parameter is indicative as it can still exist cases of \emph{false negatives} (words properly classified but labelled incorrectly) that then cut out the entire cluster.

In the following table are collected the number of clusters that respect the above described property and the number of items that they contain. 

\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabular}{|l | c | c | c |} 
 \hline 
 & \multicolumn{1}{p{2cm}|}{\centering\bfseries Correct\\ clusters}&  \multicolumn{1}{p{2cm}|}{\centering\bfseries Correct\\words} & \multicolumn{1}{p{2cm}|}{\centering\bfseries Percentage (\%)} \\ [0.5ex] 
 \hline\hline
%% label & clusters & words & percentage %%
16 scans (L1) & 12 & 18 & 3.27\\ 
16 scans (LCS) & 33 & 44 & 8.00\\ 
16 scans (LCS and L1) & 25 & 45 & 8.18\\ 
32 scans (L1) & 11 & 11 & 1.38\\ 
32 scans (LCS) & 39 & 48 & 6.00\\ 
32 scans (LCS and L1) & 32 & 43 & 5.38\\ 
80 scans (L1) & 39 & 172 & 7.32\\ 
80 scans (LCS) & 78 & 265 & 11.28\\ 
80 scans (LCS and L1) & 77 & 316 & 13.45\\ 
160 scans (L1) & 138 & 651 & 12.89\\ 
160 scans (LCS) & 208 & 713 & 14.12\\ 
160 scans (LCS and L1) & 215 & 860 & 17.03\\ 
700 scans (L1) & 0 & 0 & 0\\ 
700 scans (LCS) & 0 & 0 & 0\\ 
700 scans (LCS and L1) & 0 & 0 & 0\\ 
 \hline
\end{tabular}
\caption{Correct clusters}
\label{table:2}
\end{table}
