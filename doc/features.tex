\section{Features extraction and implementation}

In this work we want to improve upon the previous project by providing an alternate method to calculate the distances, the focus isn't any more speed and simplicity but rather even at a major cost we want to find characteristics more deeply related to the handwritten words nature in hope they may be better suited for the recognition of similar handwritten words.

The idea is thus to find \emph{primitive} features, resembling the possible types of strokes used to write a word, to characterize the sample from which they are extracted in order to perform clustering on their set.

In particular due to the way the code was implemented the feature extraction follows immediately the segmentation of the image and can thus be executed in sequence within the same threads without adding great complexity to the process.

\vspace{2mm}

The feature extraction and implementation step can be summarized in:
\begin{itemize}
\item Operate a sliding window to scan a cut-out image
\item Find the structural features belonging to the given window
\item Associate the strings corresponding to the features to the window, creating a bigger string
\item Create the string corresponding to the whole cut-out image from the fusion of the strings associated to the windows
\end{itemize}

\subsection{Structural features}

The features are identified by the study of a sub-portion, or window, of the images correspondent to the entries of the "State" field of the census document on which the procedure is applied.

The features that we search are intrinsically characteristics of the stroke, they are located through the study of the area (the window), with which they are implicitly associated; this poses a problem: there is the possibility that an area may be characterized by multiple features, in this case there is no clear order of which of the multiple features comes first.
Due to the absence of such \emph{native} order the string that defines a window is maintained consistent with the other strings trough the convention of generating the string with the features' identifiers always taking the same order, if present.

The chosen way to resolve the issue however presents the problem of making sliding windows not directly applicable: this means that a sample must necessarily be cut in separate windows, which are allowed to overlap, with the result that, due to the random cut, some features like \textit{loops} may not be recognised in an instance and recognised in another. 

Each sample is associated to a characterizing string of characters made from the ordered identifiers of the windows in the sample, each window's string is itself made from the identifier strings of the features recognized in the sample.
The features that convey more information about a word or are more precisely identified, for example loops and dots, are associated to longer strings so that their presence may be better recognised.

After having recognised the presence of a feature in a given window the corresponding identifier is added to the end of the string correspondent to the window; the order in which the features are searched and thus added to the queue is decided a priori and maintained consistent during the construction of the strings. 


\paragraph{Windows}

Currently the samples(the cut-out images) are cut in windows of 40 pixels each, with the exception of the last segment of the sample that, deemed irrelevant to the end of characterization since it contains almost always white space, is simply ignored.

These windows are spaced 7 pixels from the preceding and succeeding ones, with the intent of creating overlap and lengthening the string that characterizes the samples: the lengthening allows more precision in the clustering phase increasing the distance between strings.
(Both the dimension of the window and the spacing between them was decided through tests to obtain the optimal efficacy of the program)

\begin{figure}[!htpb]
\centering
\includegraphics[width=0.19\textwidth]{images/sliding.jpg}
\caption{Overlapping windows 40 pixels wide, spaced 7 pixels}
\end{figure} 



While the simplest way to create the windows in the code would be simply cutting the original image in pieces through specialized functions of the \textit{Leptonica} library, these steps require a great amount of memory and time. We have thus preferred to increase the complexity of the functions that search for the features, to whom we pass as a variable the original images with information about the \textit{offset} at which to start the search and the \textit{width} of the window. The width of the window passed has actually a non banal meaning due to the fact that different features are associated with areas of the image with varying dimensions: for example it is not sensible to search for an horizontal line and a vertical line utilizing windows with the same width due to the fact that horizontal lines realistically will require windows with great width but will not have requisites on the height.


In particular, the features with less space requirements are searched in both 20 pixels halves of the windows and their strings are appended to the image string, the whole 40 pixels window is then searched for the space-hungry features, only then their identifiers are added to the general string. 

\begin{figure}[!htpb]
\centering
\includegraphics[width=0.4\textwidth]{images/missouri_windows.jpg}
\caption{A window (40px) and its first half(20px)}
\end{figure} 

The height of the windows used is never considered as a parameter since for all the features searching functions the height is customarily the height of the sample.  

\subsubsection{Whitespace}  

The first feature that is searched in the windows is the presence of white space. If a window is identified as blank there will not be a need to proceed with the search of the other features, saving time.

\begin{figure}[!htpb]
\centering
\includegraphics[width=0.06\textwidth]{images/whitespace.jpg}
\caption{A \textit{Whitespace}}
\end{figure} 

A window is identified as blank if the average pixel values is below a pre-set threshold.

The string associated with the \textit{Whitespace} is " ".
This string is not given much consideration when calculating distances since it may bring problems if images with the same word are not properly centered in the segmented samples, while differentiating words through the presence of spaces does not bring significant improvement.

\subsubsection{Loop}

The feature that represents a loop requires the search of the whole 40 pixels window.
The localization of a loop starts from the search of a black pixel. The idea behind this approach is that a point on the border of a loop is such that by looking in a pre-defined direction (in this case the y axis) we find two pixel's value transitions first from black to white and then from white to black. Between the two transitions for a loop to be recognised there must be a minimum number of white pixels.

\begin{wrapfigure}{l}{0.3\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[width=0.06\textwidth]{images/loop.jpg}
  \end{center}
  \vspace{-20pt}
  \caption{A loop}
  \vspace{-10pt}
\end{wrapfigure}

To recognise a loop the above condition must also be verified in the other cardinal axis. To do so, starting from the center of the supposed loop (the median value of the segment described above) we check that moving either right or left we find a transition from white to black after a suitable number of white pixels.

The implemented method has numerous problems related to the difficulty of finding the best white spaces threshold: an excessively little minimum number of white pixels makes us recognise as loops white noise that happens while scanning images, a threshold too high forces us to discard some small but real loops. The method also does not take into account the thickness of the stroke, rendering the overall recognition harder, with appropriate threshold values tough we can achieve good results.

The string associated with the \textit{Loop} feature is "LL".
\subsubsection{Dot}

\begin{wrapfigure}{r}{0.3\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[width=0.08\textwidth]{images/dot}
  \end{center}
  \vspace{-20pt}
  \caption{A dot}
  \vspace{-10pt}
\end{wrapfigure}

To search for \textit{Dots} within the segment we first proceed locating the \emph{connected components} inside of it. The individual components are extracted and inserted into a \emph{box} of which we know the size and the relative position to the segment.


At this point we search for those boxes with dimensions between two pre-set values (minimum and maximum radius), those that meet this condition are boxes that most likely contain  points.
Using the connected components we can thus retrieve dots in a simple way.

The string associated with the Dot feature is ".....".

This string is especially long because the dot helps distinguish the words that contain the "i" letter and a dot is easily recognised with little error.

\subsubsection{Diagonal line}

The feature representing a diagonal line, both upward and downward facing, is extracted through a simple exhaustive scan of the window looking for lines of connected black pixels that have an inclination in a range of values and are sufficiently large.

In the case of an upward facing diagonal, given a black pixel we consider it connected to another black pixel if this second one is in one of 3 different position that are illustrated in Figure \ref{pixels}. The lines recognized are thus all those with gradient between 30 and 60\%.

\begin{figure}[!htpb]
\centering
\includegraphics[width=0.12\textwidth]{images/diagP.jpg}
\caption{Given the black pixel we search for other black pixels in the 3 positions, the closer red one is given priority}
\label{pixels}
\end{figure} 
\vspace{3mm}
At the moment the function doesn't account for the width of the lines found, thus diagonal features can be recognised in a formless blob of black pixels that is sufficiently big. 

\begin{figure}[!htpb]
 \centering
 \subfigure[]
   {\includegraphics[width=0.07\textwidth]{images/diagonal.jpg}}
 \hspace{15mm}
 \subfigure[]
   {\includegraphics[width=0.046\textwidth]{images/blob.jpg}}
 \caption{proper \textit{Diagonal} feature(a) and a formless blob that introduces errors(b), in this second both upward and downward diagonal lines are recognised}
  \end{figure}
\vspace{2mm}
   
A distinction in the associated string is introduced for the diagonal features that appear in the lower or upper bottom of the window, moreover the searches for the two kinds of lines are separate.
At most in a window the function identifies a couple of upward and a couple of downward facing lines (lower and upper parts), once one has been found it stops searching for the same type.
The lines that are found are further categorised on their length if medium or long.

Many different strings are associated with the \textit{Diagonal} feature, they are properly listed in Table \ref{features}.
In particular the string associated with the "long" version of a feature is made from the string associated with the "medium" version of the feature prefixed with an additional character: this allows to distinguish features based on their length while at the same time maintaining similarity with a shorter version of themselves to account for variation in the stroke used to write the same word.  
 
\subsubsection{Cross}
The function, having found at most a lower and upper case for upward and downward diagonal lines, proceeds to compare the edge points of these lines: if they possibly intersects it extracts a \emph{crossing} feature with distinction if the crossing happens in the lower or upper part of the window, priority is given to the bottom part if for example a bottom upward diagonal intersects an upper downward diagonal. 

The problems with this sub-feature are that intersections of bottom and upper lines of the same type (e.g. both upward facing) with different inclines are not recognised, in the same way there's no consideration for intersections made from lines that are not the "primary" bottom and upper diagonals: if in a single windows are present more lower upwards diagonals and one of them other than the first intersects the recognised downward diagonal, such a crossing is ignored.

\begin{wrapfigure}{l}{0.3\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[width=0.08\textwidth]{images/cross.jpg}
  \end{center}
  \vspace{-20pt}
  \caption{A cross}
  \vspace{-10pt}
\end{wrapfigure}


The crossing feature may also not necessarily be a complete intersection, in fact for recognition there just needs to be a merging of a downward and upward line. 

The string associated, depending if the cross is found in the upper or lower half, is "X" and "x" respectively.
While it may seem that a crossing is distinctive of a word and thus deserving of more "characterizing force", that is the length of the associated strings, the difficulty in recognising the feature and it's uncertainty renders an excessive weight given to its presence dangerous for clustering purposes.
The feature is thus maintained for future improvements but doesn't bring immediate 
contributions to the application.

\subsubsection{Horizontal and Vertical line}
Both horizontal and vertical lines' features are extracted through
a simple scan of the window.

The horizontal lines require a double-window for their implicit characteristic.
The function identifies a line if it finds a connected row or column of black pixels that has sufficient length, in particular it distinguishes the lines found in normal or long through an additional threshold.
In particular, as obvious difference from the diagonal line, no play is left to recognise inclined lines as horizontal or vertical.

Once a fitting line has been found the function keeps searching for more until the exhaustion of the assigned window. The scansion of the window is continued after having moved a certain distance from the last line found in order not to confuse a particularly thick stroke as different separate lines.
The corresponding string as thus no limitation in length other than the ones posed by the maximum number of lines that can fit in a window.

\begin{figure}[!htpb]
 \centering
 \subfigure[]
   {\includegraphics[width=0.07\textwidth]{images/hor.jpg}}
 \hspace{15mm}
 \subfigure[]
   {\includegraphics[width=0.05\textwidth]{images/ver.jpg}}
 \caption{Horizontal(a) and Vertical(b) features}
  \end{figure}
\vspace{2mm}

There still persists the problem that the stroke width is not fully considered so a big blob of black pixels is seen as a series of horizontal and vertical lines, at the same time such an occurrence is rare so the presence of many horizontal and vertical lines ends up distinguishing the word in itself.    
\newpage
\subsubsection*{Recapitulation}
Follows a recapitulation of the various features and their associated strings in Table \ref{features}.
In the \textit{Simplified} column are contained the corresponding strings utilized in the example of features' extraction of Section \ref{FEE}.
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{|l | c | c |} 
 \hline  \multicolumn{1}{|p{2cm}|}{\bfseries Feature}
 & \multicolumn{1}{p{2cm}|}{\centering\bfseries Associated string}  & \multicolumn{1}{p{2cm}|}{\centering\bfseries Simplified string} \\ [0.5ex] 
 \hline\hline
 Whitespace & " " & " "\\ \hline
 Loop & "LL" & "L"\\\hline
 Dot & "....." & "."\\ \hline
 Upward facing diagonal lower half, medium & "s" & "s" \\ \hline
 Upward facing diagonal lower half, long & "bs" & "s" \\\hline
 Upward facing diagonal upper half, medium & "S"& "S" \\ \hline
 Upward facing diagonal upper half, long & "BS" & "S"\\\hline
 Downward facing diagonal lower half, medium& "u"& "u"\\ \hline
 Downward facing diagonal lower half, long &"vu" & "u"\\ \hline
 Downward facing diagonal upper half, medium& "U" & "U"\\\hline
 Downward facing diagonal upper half, long &"VU" & "U"\\\hline
 Cross upper & "X"& "X"\\\hline
 Cross lower & "x"& "x"\\\hline
 Horizontal line lower half, medium & "-"& "H"\\\hline
  Horizontal line lower half, long & "h-"& "H"\\\hline
   Horizontal line upper half, medium & "H-"& "H"\\\hline
    Horizontal line upper half, long & "Hh-"& "H"\\\hline
 Vertical line lower half, medium & "ii"& "V"\\\hline
  Vertical line lower half, long & "IIii"& "V"\\\hline
   Vertical line upper half, medium & "Vii"& "V"\\\hline
    Vertical line upper half, long & "VIIii"& "V"\\ 
 \hline
\end{tabular}
\caption{Recapitulation of the strings associated to each feature}
\label{features}
\end{table}



\subsection{Dimensional features}
While the already proposed structural features help in categorizing and recognising words to cluster, they are not completely able to distinguish a word from similar others, we have thus searched for ways to improve the accuracy of the application:
while many optimizations have been added to the defined structural features we have found that adding another layer of features of a different kind, in this case \emph{dimensional}, helps greatly.
Moreover the complexity added is extremely limited: as can be seen later on in the Table \ref{table:2} the required calculation time does not increase in a particularly meaningful way: the majority of the process complexity is not located in the features' extraction but rather in the construction of the LCS-distance matrix and in the clustering.  
Thus in order to improve word clustering we combine structural features with \emph{dimensional features} for each word, after constructing the distance matrices for both we combine them through a factor determined from testing. 

These dimensional features are exactly the ones previously utilized by our colleagues in the pre-existing work: height of the stroke, calculated through the difference between highest and lowest black pixel, and number of transition of the pixels' value from black to white and vice versa.

A simple explanation on how they are extracted can be found in section \ref{oldFeatures}.

\subsection{Features extraction example}
\label{FEE}
Follows an example of features extraction from a word sample.
In this particular example are utilized simplified strings associated to each feature (for the relations consult Table \ref{features}).

We initially create, as described in the section above, a sliding window that scrolls along the image by a fixed step. Then, for each section, we extract features and generate a substring.

\begin{figure}[!htpb]
\centering
\includegraphics[width=0.5\textwidth]{images/missouri_crop.jpg}
\caption{Feature extraction from \emph{Missouri} word}
\end{figure} 

\begin{figure}[!htpb]
 \centering
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/0.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/1.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/2.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/3.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/4.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/5.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/6.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/7.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/8.jpg}}} 
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/9.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/10.jpg}}}
 \subfigure[]
   {\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/11.png}}}
 \caption{Sliding window segmentation}
 \end{figure}

\begin{enumerate}[label=(\alph*)]
\item Some \textbf{diagonal lines} (ascending (s) and descending (u) ), at the top (S) and at the bottom (s) of the image. Generated string: ''\emph{sSUusSUSu}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/0.jpg}}
\end{figure} 
\item As the previous image and two more diagonal lines representing the "\emph{i}". An \textbf{horizonal line} (H). Generated string: ''\emph{sSUusSUSuHsu}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/1.jpg}}
\end{figure} 
\item Some diagonal lines and, at the end of the window, an horizontal line. Generated string: ''\emph{ssSusSsH}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/2.jpg}}
\end{figure} 
\item Two consecutive similar character represented by diagonal lines and \textbf{vertical lines} in the middle. Generated string: ''\emph{sVHsV}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/3.jpg}}
\end{figure} 
\item In that window we can find a \textbf{dot} (.). Generated string: ''\emph{ssVHs.}''
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/4.jpg}}
\end{figure} 
\item The same previous dot and a little \textbf{loop} (L) at the bottom. Generated string: ''\emph{ssVs.LssH}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/5.jpg}}
\end{figure} 
\item The same loop as previous, an horizontal line a vertical line and two diagonal. Generated string: ''\emph{LVHssu}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/6.jpg}}
\end{figure} 
\item Generated string: ''\emph{ssVHus}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/7.jpg}}
\end{figure} 
\item The other dot here. Generated string ''\emph{ssus.H}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/8.jpg}}
\end{figure} 
\item An i. Generated string: ''\emph{ssuu.}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/9.jpg}}
\end{figure} 
\item Only a diagonal line. Generated string: ''\emph{s}''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/10.jpg}}
\end{figure} 
\item Empty window. Generated string: ''\emph{ }''.
\begin{figure}[H]
\centering
\fbox{\includegraphics[width=0.06\textwidth]{images/missouri/11.png}}
\end{figure} 
\end{enumerate}
The resulting string is: \newline \emph{"sSUusSUSusSUusSUSuHsussSusSsHsVHsVssVHsssVs.LssHLVHssussVHusssus.Hssuu.s"}

\vspace{3mm}

Once those strings are generated they are combined together to generate the \textit{structure string} associated with the word sample. 

